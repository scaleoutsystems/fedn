{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "622f7047",
   "metadata": {},
   "source": [
    "## Asycronous clients\n",
    "\n",
    "This example illustrates how one can work with asyncronous clients using FEDn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2686dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from client.entrypoint import compile_model, load_parameters, make_data \n",
    "\n",
    "\n",
    "from fedn import APIClient\n",
    "import uuid\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ab4a64",
   "metadata": {},
   "source": [
    "### ML model\n",
    "\n",
    "As a centralized model baseline we generate synthetic data for a classification problem with 4 features. We train a MLPClassifier on 80k training points, and test on 20k using ReLU activation, and Adam as optimizer, using a maximum of 1000 epochs.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c5f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=100000, n_features=4, n_informative=4, n_redundant=0, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a121b39",
   "metadata": {},
   "source": [
    "We train a centralized baseline model for a maximum of 1000 epochs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a985c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "central_test_acc = accuracy_score(y_test, clf.predict(X_test))\n",
    "\n",
    "print(\"Training accuracy: \", accuracy_score(y_train, clf.predict(X_train)))\n",
    "print(\"Test accuracy: \", accuracy_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4976986",
   "metadata": {},
   "source": [
    "Next we simulate the FL training procedure of a single FL client. The client will in each iteration (=simulated global round) draw a random number of data points in the interval (n_min, n_max) from (X_train, y_train) and perform 'n_epochs' partial fits on the sampled dataset. Then for each global round we test on the centralized test set (X_test, y_test). In this experiment we simulate 600 global rounds. The client performs 10 local epochs in each round. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ce6b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = compile_model()\n",
    "\n",
    "n_global_rounds=600\n",
    "n_epochs = 10\n",
    "central_acc_one_client = []\n",
    "for i in range(n_global_rounds):\n",
    "    x,y,_,_ = make_data(n_min=10,n_max=100)\n",
    "    for j in range(n_epochs):\n",
    "        clf.partial_fit(x, y)\n",
    "    central_acc_one_client.append(accuracy_score(y_test, clf.predict(X_test)))\n",
    "\n",
    "plt.plot(range(n_global_rounds),[central_test_acc]*n_global_rounds)\n",
    "plt.plot(range(n_global_rounds), central_acc_one_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfb237f",
   "metadata": {},
   "source": [
    "Here we simulate the scenario that a number 'n_clients' clients send locally collected/sampled datasets to a central server (by scaling n_min and n_max by n_clients). The server then performs incremenatal learning using the collected data batches (which are thus larger than in the experiment above). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f02df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = compile_model()\n",
    "\n",
    "n_global_rounds=600\n",
    "n_epochs = 10\n",
    "n_clients = 10\n",
    "central_acc_all_clients = []\n",
    "for i in range(n_global_rounds):\n",
    "    x,y,_,_ = make_data(n_min=n_clients*10, n_max=n_clients*100)\n",
    "    for j in range(n_epochs):\n",
    "        clf.partial_fit(x, y)\n",
    "    central_acc_all_clients.append(accuracy_score(y_test, clf.predict(X_test)))\n",
    "\n",
    "plt.plot(range(n_global_rounds),[central_test_acc]*n_global_rounds)\n",
    "plt.plot(range(n_global_rounds), central_acc_one_client)\n",
    "plt.plot(range(n_global_rounds), central_acc_all_clients)\n",
    "plt.legend(['Central baseline, all data','Incremental learning, one client','Inceremental learning, all clients'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c05caf",
   "metadata": {},
   "source": [
    "### Federated learning\n",
    "\n",
    "Now we run federated learning experiments over a FEDn network. For this we will use the script 'run_clients.py' to start clients running in subprocesses on the host machine. In a separate terminal, locate into this example folder. Edit the configurations in the script as needed to test different scenarios. Once clients are up and running, you can proceed below and exectute experiments. Not that these runs can take a long time to complete, depending on the number of global rounds. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1046a4e5",
   "metadata": {},
   "source": [
    "We make a client connection to the FEDn API service. Here we assume that FEDn is deployed locally in pseudo-distributed mode with default ports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1061722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DISCOVER_HOST = '127.0.0.1'\n",
    "DISCOVER_PORT = 8092\n",
    "client = APIClient(DISCOVER_HOST, DISCOVER_PORT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc5208c",
   "metadata": {},
   "source": [
    "Initialize FEDn with the compute package and seed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49320d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "client.set_active_package('package.tgz', 'numpyhelper')\n",
    "client.set_active_model('seed.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dae077",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_config = {\n",
    "    \"helper\": \"numpyhelper\",\n",
    "    \"id\": \"run_fedavg\",\n",
    "    \"aggregator\": \"fedavg\",\n",
    "    \"round_timeout\": 20,\n",
    "    \"rounds\": 600,\n",
    "    \"validate\": False,\n",
    "    \"model_id\": initial_model,\n",
    "}\n",
    "\n",
    "session = client.start_session(**session_config)\n",
    "if session['success'] is False:\n",
    "    print(session['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29552af9",
   "metadata": {},
   "source": [
    "Next, we retrive global models for this session and score the models on the central test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdabea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fedn_model(model_id):\n",
    "\n",
    "    data = client.download_model(model_id, 'temp.npz')\n",
    "    parameters = load_parameters('temp.npz')\n",
    "    model = compile_model()\n",
    "    n = len(parameters)//2\n",
    "    model.coefs_ = parameters[:n]\n",
    "    model.intercepts_ = parameters[n:]\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296e04ee",
   "metadata": {},
   "source": [
    "Traverse the model trail and plot test accuracy on the central test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b75b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trail_fedavg = client.get_model_trail()\n",
    "\n",
    "acc_fedavg = []\n",
    "for model in model_trail_fedavg: \n",
    "    model = load_fedn_model(model['id'])\n",
    "    acc_fedavg.append(accuracy_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40db4542",
   "metadata": {},
   "source": [
    "Plot the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c3c51c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = range(1,len(acc_fedavg)+1)\n",
    "\n",
    "plt.plot(x,[central_test_acc]*len(x))\n",
    "plt.plot(range(n_global_rounds), central_acc_one_client)\n",
    "plt.plot(range(n_global_rounds), central_acc_all_clients)\n",
    "plt.plot(range(len(acc_fedavg)),acc_fedavg)\n",
    "plt.legend(['Centralized baseline', 'Incremental learning, one client','Inceremental learning, all clients', 'FL'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "21345b455230dd04cf84c108e7c182ecfe8d1aa1242b8b64881a6d2c0a5951ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
