{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "3bc6870e-24aa-4ffa-8527-bffd0ca0482d",
            "metadata": {},
            "source": [
                "# Convert Your ML Training Script to Federated Learning\n",
                "This tutorial will guide you how to take your local machine learning training script and train it in a federated setting using FEDn and Scaleout studio. Start by installing the following packages into your environment:\n",
                "- `pip install fedn`\n",
                "- `pip install numpy`\n",
                "- `pip install torch`\n",
                "- `pip install torchvision`"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ef4ce158-3320-468c-b007-7e84a8e37f37",
            "metadata": {},
            "source": [
                "## ML training example script\n",
                "We will use the mnist example to show what parts of the training algorithm that needs to be modified to fit for federated learning (FL) training.\n",
                "\n",
                "The cells below shows a typicall ML training flow implementation in pytorch. We will furter down show how to transform this into a federated training flow with FednClient. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "c4d3134e-f22c-40af-989d-439c9867acc0",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from torchvision import transforms \n",
                "from torchvision import datasets\n",
                "from torch.utils.data import DataLoader\n",
                "import torch.nn.functional as F\n",
                "\n",
                "# Download and load MNIST dataset\n",
                "transform = transforms.Compose([transforms.ToTensor()])\n",
                "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
                "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
                "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
                "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
                "\n",
                "# Check available device\n",
                "if torch.cuda.is_available():\n",
                "    device = torch.device(\"cuda\")\n",
                "elif torch.backends.mps.is_available():\n",
                "    device = torch.device(\"mps\")\n",
                "else:\n",
                "    device = torch.device(\"cpu\")\n",
                " \n",
                "# Define the neural network model\n",
                "class Net(torch.nn.Module):\n",
                "    def __init__(self):\n",
                "        super(Net, self).__init__()\n",
                "        self.fc1 = torch.nn.Linear(784, 64)\n",
                "        self.fc2 = torch.nn.Linear(64, 32)\n",
                "        self.fc3 = torch.nn.Linear(32, 10)\n",
                "\n",
                "    def forward(self, x):\n",
                "        x = torch.nn.functional.relu(self.fc1(x.reshape(x.size(0), 784)))\n",
                "        x = torch.nn.functional.dropout(x, p=0.5, training=self.training)\n",
                "        x = torch.nn.functional.relu(self.fc2(x))\n",
                "        x = torch.nn.functional.log_softmax(self.fc3(x), dim=1)\n",
                "        return x\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b5d412f4",
            "metadata": {},
            "source": [
                "## Device Configuration\n",
                "\n",
                "This cell checks the availability of different types of hardware accelerators (GPU, MPS, or CPU) and sets the device accordingly. This ensures that the training process utilizes the best available hardware for optimal performance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "a6284c05-538c-414e-a01f-af540bed681c",
            "metadata": {},
            "outputs": [],
            "source": [
                "if torch.cuda.is_available():\n",
                "    device = torch.device(\"cuda\")\n",
                "elif torch.backends.mps.is_available():\n",
                "    device = torch.device(\"mps\")\n",
                "else:\n",
                "    device = torch.device(\"cpu\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d4acd688",
            "metadata": {},
            "source": [
                "## Loading and Preparing the MNIST Dataset\n",
                "This cell sets up the MNIST dataset for training and testing a neural network in PyTorch."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "57ba56d6-2665-40b3-a5b3-b54dd45b767c",
            "metadata": {},
            "outputs": [],
            "source": [
                "from torchvision import transforms \n",
                "from torchvision import datasets\n",
                "from torch.utils.data import DataLoader\n",
                "import torch.nn.functional as F\n",
                "\n",
                "batch_size = 64\n",
                "lr = 0.01\n",
                "model = Net().to(device)\n",
                "\n",
                "# Download and load MNIST dataset\n",
                "transform = transforms.Compose([transforms.ToTensor()])\n",
                "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
                "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
                "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
                "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
                "\n",
                "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
                "criterion = torch.nn.NLLLoss()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "44ed9bee",
            "metadata": {},
            "source": [
                "## Define validation and training functions\n",
                "This cell defines the training and validation functions for the neural network."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "7c30d24e-8c7e-44c3-80b3-817ce1e68075",
            "metadata": {},
            "outputs": [],
            "source": [
                "def test(model, data_loader):\n",
                "    model.eval()\n",
                "    loss = 0\n",
                "    correct = 0\n",
                "    with torch.no_grad():\n",
                "        for data, target in data_loader:\n",
                "            data, target = data.to(device), target.to(device)\n",
                "            output = model(data)\n",
                "            loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
                "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
                "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
                "\n",
                "    loss /= len(data_loader.dataset)\n",
                "    accuracy = correct/len(data_loader.dataset)\n",
                "    return loss, accuracy\n",
                "\n",
                "def validate_model(model):\n",
                "    training_loss, training_accuracy = test(model, train_loader)\n",
                "    test_loss, test_accuracy = test(model, test_loader)\n",
                "    \n",
                "    print(f\"training loss: {training_loss:.4f}, \"\n",
                "      f\"training accuracy: {training_accuracy:.4f}, \"\n",
                "      f\"test loss: {test_loss:.4f}, \"\n",
                "      f\"test accuracy: {test_accuracy:.4f}\")\n",
                "\n",
                "def train_epoc(model, optimizer, criterion):\n",
                "    for batch_idx, (data, target) in enumerate(train_loader): \n",
                "        data, target = data.to(device), target.to(device)\n",
                "        optimizer.zero_grad()\n",
                "        output = model(data)\n",
                "        loss = criterion(output, target)\n",
                "        loss.backward()\n",
                "        optimizer.step()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5b582beb",
            "metadata": {},
            "source": [
                "## Finally, the training loop\n",
                "This cell trains the neural network using the training and validation functions defined earlier."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "93e805d3",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training loop\n",
                "epochs = 2\n",
                "for epoch in range(epochs):\n",
                "    print(\"epoch: \", epoch+1, \"/\", epochs)\n",
                "    train_epoc(model, optimizer, criterion)\n",
                "    validate_model(model)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cdc907b2-87f2-4bc4-8d04-2dd5a87ee83b",
            "metadata": {},
            "source": [
                "## Initiate FL server\n",
                "Before we create our FL flow we need to create a fl project in Scaleout studio.\n",
                "- Register a FEDn account: https://fedn.scaleoutsystems.com\n",
                "- Create a project\n",
                "- Go to project settings copy the project url and generate a client token"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "32bfd056-be7f-4ebc-ae9b-a8a839b2b868",
            "metadata": {},
            "outputs": [],
            "source": [
                "project_url = \"<paste-project-url-here>\"\n",
                "client_token = \"<paste-client-token-here>\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f7f70231-d634-40f4-b40b-c87e7a994d81",
            "metadata": {},
            "source": [
                "### Create a seed model\n",
                "We initiate a new model state and save it locally first."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "123d03ed-6978-4cbb-8332-3aba83b6e530",
            "metadata": {},
            "outputs": [],
            "source": [
                "from fedn.utils.helpers.helpers import get_helper\n",
                "\n",
                "HELPER_MODULE = \"numpyhelper\"\n",
                "helper = get_helper(HELPER_MODULE)\n",
                "\n",
                "model = Net().to(device)\n",
                "parameters_np = [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
                "seed_local_path = \"mnist_seed.npz\"\n",
                "helper.save(parameters_np, seed_local_path)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "27eda8d0-3992-4869-8e2d-785d1a584c4a",
            "metadata": {},
            "source": [
                "### Upload the seed model the server\n",
                "Navigate to https://fedn.scaleoutsystems.com/models/add-seed-model and upload the seed model generated in the previous cell."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "502e308a-54e3-4fd3-a191-695e02d8f60b",
            "metadata": {},
            "source": [
                "## FL training client\n",
                "Now that the server is up and running, we can start the FL training client. The client will connect to the server and start training the model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "5ad91dbb-5eb9-49e1-b77e-c50fe5d99e15",
            "metadata": {},
            "outputs": [],
            "source": [
                "import io\n",
                "import os\n",
                "import collections\n",
                "from fedn.utils.helpers.helpers import get_helper\n",
                "import collections\n",
                "\n",
                "HELPER_MODULE = \"numpyhelper\"\n",
                "helper = get_helper(HELPER_MODULE)\n",
                "\n",
                "def load_weights_into_model(weights, model):\n",
                "    \n",
                "    inpath = helper.get_tmp_path()\n",
                "    with open(inpath, \"wb\") as fh:\n",
                "        fh.write(weights.getbuffer())\n",
                "    weights = helper.load(inpath)\n",
                "    os.unlink(inpath)\n",
                "    params_dict = zip(model.state_dict().keys(), weights)\n",
                "    state_dict = collections.OrderedDict({key: torch.tensor(x) for key, x in params_dict})\n",
                "    model.load_state_dict(state_dict, strict=True)\n",
                "\n",
                "    \n",
                "\n",
                "def extract_weights_from_model(model):\n",
                "\n",
                "    # Convert from pytorch weights format numpy array \n",
                "    updated_weights = [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
                "    outpath = helper.get_tmp_path()\n",
                "    helper.save(updated_weights, outpath)\n",
                "    with open(outpath, \"rb\") as fr:\n",
                "        out_model = io.BytesIO(fr.read())\n",
                "    os.unlink(outpath)\n",
                "\n",
                "    return out_model"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d9517daf",
            "metadata": {},
            "source": [
                "## Define the training logic\n",
                "This cell defines the training logic for the FL client. This is where the training algorithm is modified to fit the federated learning setting. This code will run when the server sends a request to the client to train the model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "a278edf9-d02b-44fc-9b30-2155a4628a38",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "from fedn.utils.helpers.helpers import save_metadata\n",
                "import json\n",
                "\n",
                "model = Net().to(device)\n",
                "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
                "criterion = torch.nn.NLLLoss()\n",
                "\n",
                "def training_round(weights, client_settings):\n",
                "\n",
                "    # Convert from numpy array to correct pytorch format\n",
                "    load_weights_into_model(weights, model)\n",
                "    \n",
                "    validate_model(model)\n",
                "    \n",
                "    # Training loop\n",
                "    local_epochs = 1\n",
                "    for epoch in range(local_epochs): \n",
                "        train_epoc(model, optimizer, criterion)\n",
                "\n",
                "    validate_model(model)\n",
                "    \n",
                "\n",
                "    metadata = {\"training_metadata\":{\n",
                "        # num_examples are mandatory\n",
                "        \"num_examples\": train_loader.dataset.data.shape[0],\n",
                "        \"batch_size\": train_loader.batch_size,\n",
                "        \"epochs\": local_epochs,\n",
                "        \"lr\": lr,\n",
                "    }}\n",
                "   \n",
                "    out_model = extract_weights_from_model(model)\n",
                "\n",
                "    outpath = \"temp\"\n",
                "    save_metadata(metadata, outpath)\n",
                "    with open(outpath + \"-metadata\", \"r\") as fh:\n",
                "                training_metadata = json.loads(fh.read())\n",
                "    \n",
                "    os.unlink(outpath + \"-metadata\")\n",
                "    return out_model, training_metadata"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ad4961d3",
            "metadata": {},
            "source": [
                "## Define the validation logic\n",
                "This cell defines the validation logic for the FL client. This code will run when the server sends a request to the client to validate the model. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "7bb88c26-501e-4fc5-a3d1-f5b0afb7db17",
            "metadata": {},
            "outputs": [],
            "source": [
                "def validate_weights(weights):\n",
                "\n",
                "    # Convert from numpy array to correct pytorch format\n",
                "    load_weights_into_model(weights, model)\n",
                "    \n",
                "    \n",
                "    training_loss, training_accuracy = test(model, train_loader)\n",
                "    test_loss, test_accuracy = test(model, test_loader)\n",
                "    # JSON schema\n",
                "    performance = {\n",
                "        \"training_loss\": training_loss,\n",
                "        \"training_accuracy\": training_accuracy,\n",
                "        \"test_loss\": test_loss,\n",
                "        \"test_accuracy\": test_accuracy,\n",
                "    }\n",
                "\n",
                "    return performance"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fd81dcd8-3cea-4d1d-a333-ac899a3527e8",
            "metadata": {},
            "source": [
                "## Configure the client\n",
                "This cell configures the client to connect to the server and start training the model. Generating a client id and specifying the client name. The client id is used to identify the client when connecting to the server. This way a client is reconized by the server when reconnected. The name is used for simlicity for the user and should be set to something descriptive."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "25a80aaf-e986-4dd4-aa66-c0226e3812b9",
            "metadata": {},
            "outputs": [],
            "source": [
                "from fedn.network.clients.fedn_client import FednClient, ConnectToApiResult\n",
                "import uuid\n",
                "\n",
                "fedn_client = FednClient(train_callback=training_round, validate_callback=validate_weights)\n",
                "\n",
                "name = \"<write-client-name-here>\"\n",
                "client_id = str(uuid.uuid4())\n",
                "\n",
                "fedn_client.set_name(name)\n",
                "fedn_client.set_client_id(client_id)\n",
                "\n",
                "controller_config = {\n",
                "    \"name\": name,\n",
                "    \"client_id\": client_id,\n",
                "    \"package\": \"local\",\n",
                "    \"preferred_combiner\": \"\",\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0e4c03e9-b73d-4d77-b794-3462df1b3659",
            "metadata": {},
            "source": [
                "## Connect client to fedn network\n",
                "The client will connect to the server first via http and then handle the communication via grpc. The rest call returns a grpc endpoint that the client will use to connect to the server. This works as a discovery service for the client to find the server. If the grpc enpoint is already known (for example if there is only one combiner in the project) the client can connect directly to the grpc endpoints. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3c0f725a-f005-4a46-b466-7de9f1cfd143",
            "metadata": {},
            "outputs": [],
            "source": [
                "result, combiner_config = fedn_client.connect_to_api(f\"https://{project_url}/\", client_token, controller_config)\n",
                "\n",
                "if result != ConnectToApiResult.Assigned:\n",
                "    print(\"Failed to connect to API, exiting.\")\n",
                "    exit (1)\n",
                "\n",
                "result: bool = fedn_client.init_grpchandler(config=combiner_config, client_name=name, token=client_token)\n",
                "\n",
                "if not result:\n",
                "    exit (1)\n",
                "else:\n",
                "    print(\"Client connected to network.\")\n",
                "\n",
                "fedn_client.run()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3b092b8f",
            "metadata": {},
            "source": [
                "## Start training session\n",
                "Now navigate to https://fedn.scaleoutsystems.com/sessions/create-session and create a new session. From the session page you can start the session and the client will start training the model. You can follow the training progress in the session page."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "niklas",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}