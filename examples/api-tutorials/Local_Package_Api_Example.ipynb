{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bc6870e-24aa-4ffa-8527-bffd0ca0482d",
   "metadata": {},
   "source": [
    "# Convert Your ML Training Script to Federated Learning\n",
    "This tutorial guides you through converting a local machine learning training script into a federated learning setup using FEDn and Scaleout Studio. While most of our examples use a remote package—where training and validation functions are defined on the server—this example defines the training and validation functions locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4ce158-3320-468c-b007-7e84a8e37f37",
   "metadata": {},
   "source": [
    "## ML training example script\n",
    "We will use the mnist example to show what parts of the training algorithm that needs to be modified to fit for federated learning (FL) training.\n",
    "\n",
    "The cells below shows a typicall ML training flow implementation in pytorch. We will furter down show how to transform this into a federated training flow with FednClient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4d3134e-f22c-40af-989d-439c9867acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms \n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Download and load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Check available device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    " \n",
    "# Define the neural network model\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(784, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.fc1(x.reshape(x.size(0), 784)))\n",
    "        x = torch.nn.functional.dropout(x, p=0.5, training=self.training)\n",
    "        x = torch.nn.functional.relu(self.fc2(x))\n",
    "        x = torch.nn.functional.log_softmax(self.fc3(x), dim=1)\n",
    "        return x\n",
    "\n",
    "def test(model, data_loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    loss /= len(data_loader.dataset)\n",
    "    accuracy = correct/len(data_loader.dataset)\n",
    "    return loss, accuracy\n",
    "\n",
    "def validate_model(model):\n",
    "    \n",
    "    training_loss, training_accuracy = test(model, train_loader)\n",
    "    test_loss, test_accuracy = test(model, test_loader)\n",
    "    \n",
    "    \n",
    "    print(f\"training loss: {training_loss:.4f}, \"\n",
    "      f\"training accuracy: {training_accuracy:.4f}, \"\n",
    "      f\"test loss: {test_loss:.4f}, \"\n",
    "      f\"test accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "def train_epoc(model, optimizer, criterion):\n",
    "    \n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader): \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c30d24e-8c7e-44c3-80b3-817ce1e68075",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "model = Net().to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "\n",
    "# Training loop\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    print(\"epoch: \", epoch+1, \"/\", epochs)\n",
    "    train_epoc(model, optimizer, criterion)\n",
    "    validate_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc907b2-87f2-4bc4-8d04-2dd5a87ee83b",
   "metadata": {},
   "source": [
    "## Initiate FL server\n",
    "Before we create our FL flow we need to create a fl project in Scaleout studio.\n",
    "- Register a FEDn account: https://fedn.scaleoutsystems.com\n",
    "- Create a project\n",
    "- Go to project settings copy project url, admin token and client token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bfd056-be7f-4ebc-ae9b-a8a839b2b868",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_url = \"<paste-api-url-here>\"\n",
    "admin_token = \"<paste-admin-token-here>\"\n",
    "client_token = \"<paste-client-token-here>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f70231-d634-40f4-b40b-c87e7a994d81",
   "metadata": {},
   "source": [
    "## Initiate a model state\n",
    "We initiate a new model state and save it locally first. We can then use the FednClient to upload the model state to the server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123d03ed-6978-4cbb-8332-3aba83b6e530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedn.utils.helpers.helpers import get_helper\n",
    "from fedn import APIClient\n",
    "HELPER_MODULE = \"numpyhelper\"\n",
    "helper = get_helper(HELPER_MODULE)\n",
    "\n",
    "model = Net().to(device)\n",
    "parameters_np = [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
    "seed_local_path = \"mnist_seed.npz\"\n",
    "helper.save(parameters_np, seed_local_path)\n",
    "\n",
    "\n",
    "client = APIClient(host=project_url, token=admin_token, secure=True, verify=True)\n",
    "\n",
    "result = client.set_active_model(seed_local_path)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502e308a-54e3-4fd3-a191-695e02d8f60b",
   "metadata": {},
   "source": [
    "## FL training client\n",
    "\n",
    "We need the wrapper functions: load_weights_into_model and extract_weights_from_model to communicate the model state between the model and the FednClient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ad91dbb-5eb9-49e1-b77e-c50fe5d99e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import collections\n",
    "from fedn.utils.helpers.helpers import get_helper\n",
    "HELPER_MODULE = \"numpyhelper\"\n",
    "helper = get_helper(HELPER_MODULE)\n",
    "\n",
    "def load_weights_into_model(weights, model):\n",
    "    \n",
    "    inpath = helper.get_tmp_path()\n",
    "    with open(inpath, \"wb\") as fh:\n",
    "        fh.write(weights.getbuffer())\n",
    "    weights = helper.load(inpath)\n",
    "    os.unlink(inpath)\n",
    "    params_dict = zip(model.state_dict().keys(), weights)\n",
    "    state_dict = collections.OrderedDict({key: torch.tensor(x) for key, x in params_dict})\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    \n",
    "\n",
    "def extract_weights_from_model(model):\n",
    "\n",
    "    # Convert from pytorch weights format numpy array \n",
    "    updated_weights = [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
    "    outpath = helper.get_tmp_path()\n",
    "    helper.save(updated_weights, outpath)\n",
    "    with open(outpath, \"rb\") as fr:\n",
    "        out_model = io.BytesIO(fr.read())\n",
    "    os.unlink(outpath)\n",
    "\n",
    "    return out_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5af72d",
   "metadata": {},
   "source": [
    "The FednClient need a train_callback and validate_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a278edf9-d02b-44fc-9b30-2155a4628a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchvision import transforms \n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from fedn.utils.helpers.helpers import save_metadata\n",
    "import json\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "\n",
    "def training_round(weights, client_settings):\n",
    "\n",
    "    # Convert from numpy array to correct pytorch format\n",
    "    load_weights_into_model(weights, model)\n",
    "\n",
    "    # Training loop\n",
    "    local_epochs = 1\n",
    "    for epoch in range(local_epochs): \n",
    "        train_epoc(model, optimizer, criterion)\n",
    "\n",
    "    metadata = {\"training_metadata\":{\n",
    "        # num_examples are mandatory\n",
    "        \"num_examples\": train_loader.dataset.data.shape[0],\n",
    "        \"batch_size\": train_loader.batch_size,\n",
    "        \"epochs\": local_epochs,\n",
    "        \"lr\": lr,\n",
    "    }}\n",
    "   \n",
    "    out_model = extract_weights_from_model(model)\n",
    "\n",
    "    outpath = \"temp\"\n",
    "    save_metadata(metadata, outpath)\n",
    "    with open(outpath + \"-metadata\", \"r\") as fh:\n",
    "                training_metadata = json.loads(fh.read())\n",
    "    \n",
    "    os.unlink(outpath + \"-metadata\")\n",
    "    return out_model, training_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7bb88c26-501e-4fc5-a3d1-f5b0afb7db17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_weights(weights):\n",
    "\n",
    "    # Convert from numpy array to correct pytorch format\n",
    "    load_weights_into_model(weights, model)\n",
    "    \n",
    "    \n",
    "    training_loss, training_accuracy = test(model, train_loader)\n",
    "    test_loss, test_accuracy = test(model, test_loader)\n",
    "    # JSON schema\n",
    "    performance = {\n",
    "        \"training_loss\": training_loss,\n",
    "        \"training_accuracy\": training_accuracy,\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_accuracy\": test_accuracy,\n",
    "    }\n",
    "\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd81dcd8-3cea-4d1d-a333-ac899a3527e8",
   "metadata": {},
   "source": [
    "We then initiate the FednClient api with our train and validate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a80aaf-e986-4dd4-aa66-c0226e3812b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedn.network.clients.fedn_client import FednClient, ConnectToApiResult\n",
    "import uuid\n",
    "\n",
    "fedn_client = FednClient(train_callback=training_round, validate_callback=validate_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4c03e9-b73d-4d77-b794-3462df1b3659",
   "metadata": {},
   "source": [
    "## Connect client to fedn network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0f725a-f005-4a46-b466-7de9f1cfd143",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"<write-client-name-here>\"\n",
    "\n",
    "fedn_client.set_name(name)\n",
    "\n",
    "client_id = str(uuid.uuid4())\n",
    "fedn_client.set_client_id(client_id)\n",
    "\n",
    "controller_config = {\n",
    "    \"name\": name,\n",
    "    \"client_id\": client_id,\n",
    "    \"package\": \"local\",\n",
    "    \"preferred_combiner\": \"\",\n",
    "}\n",
    "\n",
    "\n",
    "result, combiner_config = fedn_client.connect_to_api(\"https://\"+project_url+\"/\", client_token, controller_config)\n",
    "\n",
    "print(\"result: \", result)\n",
    "print( combiner_config)\n",
    "if result != ConnectToApiResult.Assigned:\n",
    "    print(\"Failed to connect to API, exiting.\")\n",
    "    exit (1)\n",
    "\n",
    "result: bool = fedn_client.init_grpchandler(config=combiner_config, client_name=name, token=client_token)\n",
    "fedn_client.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
