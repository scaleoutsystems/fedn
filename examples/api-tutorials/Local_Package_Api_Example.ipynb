{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef4ce158-3320-468c-b007-7e84a8e37f37",
   "metadata": {},
   "source": [
    "# Standard ML training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4d3134e-f22c-40af-989d-439c9867acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from \n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(784, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.fc1(x.reshape(x.size(0), 784)))\n",
    "        x = torch.nn.functional.dropout(x, p=0.5, training=self.training)\n",
    "        x = torch.nn.functional.relu(self.fc2(x))\n",
    "        x = torch.nn.functional.log_softmax(self.fc3(x), dim=1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c30d24e-8c7e-44c3-80b3-817ce1e68075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model):\n",
    "\n",
    "    model.eval()\n",
    "    # Evaluate\n",
    "    criterion = torch.nn.NLLLoss()\n",
    "    with torch.no_grad():\n",
    "        train_out = model(x_train)\n",
    "        training_loss = criterion(train_out, y_train)\n",
    "        training_accuracy = torch.sum(torch.argmax(train_out, dim=1) == y_train) / len(train_out)\n",
    "        test_out = model(x_test)\n",
    "        test_loss = criterion(test_out, y_test)\n",
    "        test_accuracy = torch.sum(torch.argmax(test_out, dim=1) == y_test) / len(test_out)\n",
    "\n",
    "    print(\"training loss: \", training_loss.item(),\n",
    "        \", training_accuracy: \", training_accuracy.item(),\n",
    "        \", test_loss: \", test_loss.item(),\n",
    "        \", test_accuracy: \", test_accuracy.item()\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ba56d6-2665-40b3-a5b3-b54dd45b767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "model = Net()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):  \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):  \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502e308a-54e3-4fd3-a191-695e02d8f60b",
   "metadata": {},
   "source": [
    "# Federated ML training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a278edf9-d02b-44fc-9b30-2155a4628a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_round(weights):\n",
    "    # Convert from numpy array to correct pytorch format\n",
    "    params_dict = zip(model.state_dict().keys(), weights)\n",
    "    state_dict = collections.OrderedDict({key: torch.tensor(x) for key, x in params_dict})\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    model.set_weights(weights)\n",
    "\n",
    "    # Training loop\n",
    "    local_epochs = 1\n",
    "    for epoch in range(local_epochs):  \n",
    "        for batch_idx, (data, target) in enumerate(train_loader):  \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Convert from pytorch weights format numpy array \n",
    "    updated_weights = [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
    "\n",
    "    metadata = {\n",
    "        # num_examples are mandatory\n",
    "        \"num_examples\": len(x_train),\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": epochs,\n",
    "        \"lr\": lr,\n",
    "    }\n",
    "\n",
    "    return updated_weights, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb88c26-501e-4fc5-a3d1-f5b0afb7db17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_weights(weights):\n",
    "    # Convert from numpy array to correct pytorch format\n",
    "    params_dict = zip(model.state_dict().keys(), weights)\n",
    "    state_dict = collections.OrderedDict({key: torch.tensor(x) for key, x in params_dict})\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    model.set_weights(weights)\n",
    "    model.eval()\n",
    "\n",
    "    # Evaluate\n",
    "    criterion = torch.nn.NLLLoss()\n",
    "    with torch.no_grad():\n",
    "        train_out = model(x_train)\n",
    "        training_loss = criterion(train_out, y_train)\n",
    "        training_accuracy = torch.sum(torch.argmax(train_out, dim=1) == y_train) / len(train_out)\n",
    "        test_out = model(x_test)\n",
    "        test_loss = criterion(test_out, y_test)\n",
    "        test_accuracy = torch.sum(torch.argmax(test_out, dim=1) == y_test) / len(test_out)\n",
    "\n",
    "    # JSON schema\n",
    "    performance = {\n",
    "        \"training_loss\": training_loss.item(),\n",
    "        \"training_accuracy\": training_accuracy.item(),\n",
    "        \"test_loss\": test_loss.item(),\n",
    "        \"test_accuracy\": test_accuracy.item(),\n",
    "    }\n",
    "\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a80aaf-e986-4dd4-aa66-c0226e3812b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedn.network.clients.fedn_client import FednClient, ConnectToApiResult\n",
    "\n",
    "fedn_client = FednClient(train_callback=training_round, validate_callback=validate_weights)\n",
    "\n",
    "controller_url = \"<paste-controller-url-here>\"\n",
    "token = \"<paste-token-here>\"\n",
    "\n",
    "name = \"<write-client-name-here>\"\n",
    "fedn_client.set_name(name)\n",
    "\n",
    "client_id = str(uuid.uuid4())\n",
    "fedn_client.set_client_id(client_id)\n",
    "\n",
    "controller_config = {\n",
    "    \"name\": name,\n",
    "    \"client_id\": client_id,\n",
    "    \"package\": \"local\",\n",
    "    \"preferred_combiner\": \"\",\n",
    "}\n",
    "\n",
    "result, combiner_config = fedn_client.connect_to_api(controller_url, token, controller_config)\n",
    "\n",
    "if result != ConnectToApiResult.Assigned:\n",
    "    print(\"Failed to connect to API, exiting.\")\n",
    "    exit (1)\n",
    "\n",
    "result: bool = fedn_client.init_grpchandler(config=combiner_config, client_name=client_id, token=token)\n",
    "\n",
    "if not result:\n",
    "    exit (1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FEDn venv",
   "language": "python",
   "name": "venv_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
